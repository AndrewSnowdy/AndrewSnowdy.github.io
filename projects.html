<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects | Andrew Snowdy</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="style.css">
</head>
<body class="bg-white text-gray-800 font-sans">

    <div class="flex min-h-screen">
        <!-- Sidebar Navigation -->
        <aside class="w-64 bg-slate-50 border-r border-slate-200 p-8 flex-shrink-0 flex flex-col justify-between h-screen sticky top-0">
            <div>
                <div class="sticky top-8">
                    <h1 class="text-2xl font-bold text-slate-900">Andrew Snowdy</h1>
                    <p class="text-sm text-slate-600 mt-1">Electrical Engineer</p>
                    <p class="text-xs text-slate-500 font-medium uppercase tracking-wider mt-1">Embedded Systems & Controls</p>
                    
                    <nav class="mt-12">
                        <ul class="space-y-2">
                            <li><a href="index.html" class="nav-link">About Me</a></li>
                            <li><a href="projects.html" class="nav-link active">Projects</a></li>
                            <li><a href="resume.html" class="nav-link">Resume</a></li>
                        </ul>
                    </nav>
                </div>
            </div>
            
            <div class="text-xs text-slate-400 space-y-1">
                <p>Last Updated: February 2026</p>
                <p class="text-sm text-slate-500 font-normal italic">&copy; 2026 Andrew Snowdy</p>
            </div>
        </aside>

        <!-- Main Content -->
        <main class="flex-1 p-8 md:p-12 lg:p-16">
            <div class="max-w-5xl mx-auto">
                <section id="projects">
                    <h2 class="text-3xl font-bold text-slate-900 border-b border-slate-200 pb-4 mb-8">Projects</h2>
                    
                    <div class="space-y-12">


                <!-- IN PROGRESS PROJECTS -->
                        <!-- WBC + EKF QUADRUPED -->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        Whole Body Control (WBC) & EKF State Estimation 
                                        <span class="text-red-800 font-medium ml-1">[Active Development]</span>
                                    </h3>

                                    <div class="mt-1">
                                        <a href="https://github.com/AndrewSnowdy/go2_controller" target="_blank" class="text-xs font-bold tracking-widest text-blue-900 hover:text-blue-700 transition-colors">
                                            [ GitHub ]
                                        </a>
                                    </div>
                                </div>

                                <span class="text-sm font-medium text-slate-500">Current Phase: Swing-Leg</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                This project focuses on developing a robust locomotion controller for a quadruped robot. I am currently implementing a Whole Body Control (WBC) 
                                framework to manage contact forces and joint torques, paired with an Extended Kalman Filter (EKF) for fused IMU and leg odometry state estimation. 
                                The goal is to achieve stable locomotion, disterbance rejection, and possibly pedipulation (manipulation with legs).
                            </p>
                            
                            <div class="mt-8 space-y-6 max-w-2xl mx-auto">
                                    <div class="space-y-4">
                                        <div class="overflow-hidden rounded-lg shadow-md border bg-black">
                                            <video class="w-full" autoplay loop muted playsinline>
                                                <source src="videos/wbc_real.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video>
                                        </div>

                                        <div class="overflow-hidden rounded-lg shadow-md border bg-black">
                                            <video class="w-full" autoplay loop muted playsinline>
                                                <source src="videos/wbc_sim_two.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video>
                                        </div>

                                        <div class="mt-4 text-sm text-gray-600">
                                            </p>
                                                While these demonstrations appear to be a simple standing task, they represent the core control foundation for high-performance locomotion. 
                                                The system utilizes an Extended Kalman Filter (EKF) running at 800Hz to estimate the robot's floating-base state—predicting via IMU and 
                                                updating through leg kinematics under assumed contact.
                                            </p>

                                            </p>
                                                Simultaneously, a Whole Body Controller (WBC) runs at 500Hz, solving a Quadratic Program (QP) to determine optimal joint torques. 
                                                This framework manages task-space accelerations for attitude and center of mass (CoM) control while enforcing friction cone and contact 
                                                constraints. This hierarchical architecture provides the stability and data integrity required for transitioning into dynamic gait cycles 
                                                and complex terrain navigation.
                                            </p>
                                        </div>
                                    </div>
                                </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">C++</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Optimal Control</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">State Estimation</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Robotics</span>
                            </div>
                        </div>

                        <!-- AUTONOMOUS UAV -->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        Autonomous UAV Development
                                        <span class="text-red-800 font-medium ml-1">[Active Development]</span>
                                    </h3>
                                    <!-- 
                                    <div class="mt-1">
                                        <a href="https://github.com/AndrewSnowdy/go2_controller" target="_blank" class="text-xs font-bold tracking-widest text-blue-900 hover:text-blue-700 transition-colors">
                                            [ GitHub ]
                                        </a>
                                    </div>
                                     -->
                                </div>

                                <span class="text-sm font-medium text-slate-500">Current Phase: Testing</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                This project bridges the gap between high-speed flight and real-time edge computing. I am currently integrating dual-camera stereo mapping 
                                and optical flow into a custom flight stack to enable autonomous navigation in unknown environments. By optimizing the vision pipeline for 
                                low-latency throughput, we are enabling the UAV to perform aggressive maneuvers and proactive obstacle avoidance without relying on GPS or 
                                a known map.
                            </p>
                            
                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                                <div>
                                    <div class="grid grid-cols-2 gap-4">
                                        <img src="images/drone_back.jpg" alt="New Drone CAD Design" class="rounded-lg shadow-md w-full h-full object-cover border">
                                        <img src="images/drone_front.jpg" alt="Bench Testing Setup" class="rounded-lg shadow-md w-full h-full object-cover border">
                                    </div>
                                    <p class="mt-4 text-sm text-gray-600">
                                        Early development is focusing on integrating an NVIDIA Jetson compute module and stereo vision suite for an autonomous UAV. 
                                        My focus is on hardware-level configuration and benchmarking the vision pipeline to minimize latency in the perception-to-action 
                                        loop. This foundational testing is critical for ensuring stable offboard control during future autonomous maneuvers
                                    </p>
                                </div>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">MAVLink</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">PX4/ArduPilot</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Linux</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Perception</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">High Speed Processing</span>
                            </div>
                        </div>


                        <!-- HSR MOBILE MANIPULATION -->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        HSR Mobile Manipulation
                                        <span class="text-red-800 font-medium ml-1">[Active Development]</span>
                                    </h3>

                                    <div class="mt-1">
                                        <a href="https://github.com/AndrewSnowdy/hsr_mm_control" target="_blank" class="text-xs font-bold tracking-widest text-blue-900 hover:text-blue-700 transition-colors">
                                            [ GitHub ]
                                        </a>
                                    </div>
                                </div>

                                <span class="text-sm font-medium text-slate-500">Current Phase: Autonomy</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                Navigating doorway transitions remains a challenge in mobile manipulation. In environments like hospitals and corporate 
                                offices, ADA-compliant handicap buttons offer a strategic interface for robotic systems to negotiate these transitions. 
                                This project focuses on configuring a Toyota HSR robot to perform high-reliability autonomous navigation and manipulation. 
                                By developing a custom navigation stack I will have enabled the robot to integrate obstacle avoidance and precision interaction 
                                tasks, such as activating door switches and executing pick-and-place routines.
                            </p>
                            
                            <div class="mt-8 space-y-6 max-w-2xl mx-auto">
                                <div class="rounded-lg shadow-md overflow-hidden border bg-black">
                                    <video class="w-full" autoplay loop muted playsinline>
                                        <source src="videos/hsr_real.mp4" type="video/mp4">
                                        Your browser does not support the video tag.
                                    </video>
                                </div>

                                <div class="rounded-lg shadow-md overflow-hidden border bg-black">
                                    <video class="w-full" autoplay loop muted playsinline>
                                        <source src="videos/hsr_sim.mp4" type="video/mp4">
                                        Your browser does not support the video tag.
                                    </video>
                                </div>

                                <p class="mt-4 text-sm text-gray-600">
                                    These clips feature a Human Support Robot performing a handicap door-opening task. To manage the arm's trajectory, 
                                    I utilized Damped Least Squares IK to ensure robustness against kinematic singularities, with quintic splines 
                                    generating the smooth, jerk-limited motion required for delicate interactions. Currently, the system operates via 
                                    high-fidelity odometry; however, the integration of a YOLO-based perception layer is already underway to transition 
                                    from pre-defined waypoints to dynamic, autonomous target acquisition.
                                </p>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">ROS 2</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">C++</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">MoveIt</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Mobile Manipulation</span>
                            </div>
                        </div>
                        



                <!-- COMPLETED PROJECTS -->
                        <!-- ROAM Project -->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        NEURoam [Graduate Research]
                                    </h3>

                                    <div class="mt-1">
                                        <a href="https://github.com/neufieldrobotics/NeuROAM" target="_blank" class="text-xs font-bold tracking-widest text-blue-900 hover:text-blue-700 transition-colors">
                                            [ GitHub ]
                                        </a>

                                        <span class="text-xs font-bold tracking-widest text-slate-400">
                                            [ Paper (Coming Soon) ]
                                        </span>
                                    </div>
                                </div>
                                <span class="text-sm font-medium text-gray-500">2025</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                NEURoam bridges the gap between heterogeneous robotic morphologies to create a unified data acquisition system. The fleet comprised 
                                of Boston Dynamics Spot, Unitree GO2 and GO2W, AgileX Scout and Hunter platforms. Each vehicle featured a standardized sensor 
                                payload centered on an NVIDIA Jetson Orin. By executing coordinated, pre-planned trajectories across the Northeastern campus, we 
                                maintained telemetry and captured a comprehensive environmental dataset. This effort resulted in the generation of high-resolution 
                                3D maps derived from over 4 TB of processed sensor data.
                            </p>
                            
                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                            
                                <div>
                                    <img src="images/roam_point_cloud.png" alt="Single full-width image for ROAM project" class="rounded-lg shadow-md w-full object-contain border">
                                    <p class="mt-4 text-sm text-gray-600">
                                        A campus-scale reconstruction derived from one of the payloads. While the SLAM backend handled the spatial mapping, I was 
                                        responsible for the embedded architecture that ensured sub-millisecond synchronization between the LiDAR and inertial sensors. 
                                        By managing the hardware triggers and PPS (Pulse Per Second) signals on the Jetson Orin, I ensured the data integrity required 
                                        for seamless environment mapping.
                                    </p>
                                </div>

                            
                                <div>
                                    <div class="grid grid-cols-2 gap-4">
                                        <img src="images/neuroam_NOFIX.jpg" alt="Side by side image 1 for ROAM project" class="rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/neuroam_Lineup.jpg" alt="Side by side image 2 for ROAM project" class="rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <p class="mt-4 text-sm text-gray-600">
                                        On the left is a close-up of the sensor payload integrated onto a Unitree Go2 quadruped, and on the right, the lineup of robots 
                                        staged for a data collection run outside the Northeastern University engineering complex. Before deployment, the team developed 
                                        and executed a series of diagnostic validation scripts to ensure system-wide sensor synchronization. Operating in an unconstrained 
                                        campus environment introduced significant challenges, including mechanical vibration, pedestrians, and maintaining data consistency 
                                        across differing locomotion modalities.
                                    </p>
                                </div>
                                
                                <div>
                                    <div class="grid grid-cols-2 gap-4">
                                        <img src="images/roam_initial.jpg" alt="Side by side image 1 for ROAM project" class="rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/roam_outside_gps.jpg" alt="Side by side image 2 for ROAM project" class="rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <div class="mt-4 text-sm text-gray-600">
                                        <p>
                                            Shown on the left is the initial Hardware-in-the-Loop prototype used for software validation and component integration. Although 
                                            the early wiring was messy, this stage was critical for verifying communication between the NVIDIA Jetson Orin and the sensor suite, 
                                            which includes FLIR stereo cameras, Ouster LiDAR, VectorNav IMU, Zed-F9P GPS, and a doodle-labs radio.
                                        </p>
                                        <p>
                                            Outdoor testing was conducted to achieve a cold-start GNSS lock for the Zed-F9P GPS module, which served as the heartbeat for 
                                            system-wide synchronization. The GPS distributes 1Hz PPS and NMEA to the jetson and 20Hz triggers to the LiDAR and cameras, 
                                            ensuring all sensors are hardware-synchronized. By acquiring high-fidelity NMEA signals, we achieved a temporal alignment of 
                                            +/- 100ms across the fleet, enabling consistent multi-robot perception and robust inter-payload communication.
                                        </p>
                                    </div>
                                </div>

                                <div>
                                    <img src="images/roam_highbay_basestation.jpg" alt="Single full-width image for ROAM project" class="rounded-lg shadow-md w-full object-contain border">
                                    <p class="mt-4 text-sm text-gray-600">
                                        This stage of the project where the core sensor suite had basic operation, and my focus shifted to establishing robust mesh networking. 
                                        We encountered a significant hardware compatibility hurdle: legacy Doodle Labs radio modules (housed in the orange box) could not natively 
                                        interface with the newer radio versions on our payloads. After exhaustive troubleshooting, I implemented a hardware-level bridge to newer 
                                        radio units. To validate the performance of the network, I developed ROS nodes to benchmark throughput (IPERF) and latency (PING), ensuring 
                                        the mesh had sufficient diagnostics during data collections.
                                    </p>
                                </div>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Linux</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">ROS2</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Python</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Sensor Fusion</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Networking</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Electronics</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Robotics</span>
                            </div>
                        </div>

                        <!-- CSLAM ADMM optimation-->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        Decentralized Multi-Agent SLAM via Consensus Optimization
                                    </h3>

                                    <div class="mt-1">
                                        <a href="https://github.com/AndrewSnowdy/RoboticsFinal" target="_blank" class="text-xs font-bold tracking-widest text-blue-900 hover:text-blue-700 transition-colors">
                                            [ GitHub ]
                                        </a>
                                    </div>
                                </div>
                                <span class="text-sm font-medium text-gray-500">2025</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                Course project exploring decentralized back-end optimization methods for multi-robot SLAM. Implemented and evaluated local, heuristic consensus, and simplified 
                                ADMM-based approaches inspired by MESA using GTSAM. Performance was analyzed using Absolute Trajectory Error (ATE) on synthetic multi-robot datasets to study 
                                trade-offs between local accuracy, global consistency, and convergence behavior.
                            </p>
                            
                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                                <div>
                                    <img src="images/cslam_admm.png" alt="Single full-width image for ROAM project" class="rounded-lg shadow-md w-full object-contain border">
                                    <p class="mt-4 text-sm text-gray-600">
                                        Comparison of noisy odometry, locally optimized trajectories with loop closures, and decentralized SLAM under assumed synchronous communication, shown 
                                        alongside ground-truth trajectories in faint gray.
                                    </p>
                                </div>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Networking</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Robotics</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Optimization</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Python</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">C++</span>
                            </div>
                        </div>
                        
                        <!-- Robotic Arm -->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        Low Cost 3D-Printed Robotic Arm
                                    </h3>

                                    <div class="mt-1">
                                        <a href="https://github.com/AndrewSnowdy/Robotic-Arm" target="_blank" class="text-xs font-bold tracking-widest text-blue-900 hover:text-blue-700 transition-colors">
                                            [ GitHub ]
                                        </a>
                                    </div>
                                </div>
                                <span class="text-sm font-medium text-gray-500">2024 - 2025</span>
                            </div>
                            <div class="mt-1 text-gray-600">
                                <p>
                                    I started this project because I believe that lack of access to industrial-grade hardware shouldn't be a barrier to learning robotics. My goal was to design an arm 
                                    that anyone could build on a budget, without sacrificing the accuracy and performance typically reserved for expensive commercial systems.
                                </p>

                                <p>
                                    The heart of this build—and the most challenging engineering hurdle—lies in the actuators. High precision and high torque are traditionally difficult to achieve with 
                                    3D-printed components, but by taking a fresh approach to gearbox design and FOC control, I’ve been able to bring this arm to life.
                                </p>

                                <p>
                                    Currently, I am finalizing a custom UI and prepping the project for a full open-source release on GitHub. Stay tuned for more updates as I move into complex 
                                    manipulation tasks and refined motion planning.
                                </p>

                            </div>
                            
                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                                <div>
                                    <div class="grid grid-cols-2 gap-4">
                                        <img src="images/arm_full_build.jpg" alt="Side by side image 1 for ROAM project" class="rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/arm_fusion.png" alt="Side by side image 2 for ROAM project" class="rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <p class="mt-4 text-sm text-gray-600">
                                        The full build of the arm (left) alongside the Fusion 360 model (right) highlights the mechanical packaging and weight distribution of the system. By moving the motors 
                                        as close to the base pivots as possible and utilizing timing belt drives, I’ve significantly reduced joint inertia. The wrist was designed to be purely spherical, 
                                        allowing Pieper's criteria to hold for efficient, closed-form analytic IK. For the end effector, I've integrated dual FeeTech STS3032 servos paired with compliant 
                                        material so fingers can wrap around objects for a secure grip, while the servos provide real-time torque feedback. The entire system is powered by a compact, 
                                        detachable dual 24V PSU.
                                    </p>
                                </div>
                                
                                <div>
                                    <div class="w-full bg-slate-100 rounded-lg overflow-hidden shadow-md mb-4">
                                        <img src="images/arm_actuators.jpg" alt="Description" class="w-full h-auto object-cover">
                                    </div>

                                    <div class="grid grid-cols-1 md:grid-cols-5 gap-4">
                                        
                                        <div class="md:col-span-2 bg-black rounded-lg overflow-hidden shadow-md">
                                            <video 
                                                class="w-full h-full object-cover" 
                                                autoplay loop muted playsinline>    
                                                <source src="videos/arm_torque_test_shorter.mp4" type="video/mp4">
                                                Your browser does not support the video tag.
                                            </video>
                                        </div>

                                        <div class="md:col-span-3 aspect-square bg-slate-100 rounded-lg overflow-hidden shadow-md">
                                            <img src="images/arm_cycloidal.png" alt="Physical build" class="w-full h-full object-cover">
                                        </div>

                                    </div>
                                    
                                    <p class="mt-4 text-sm text-gray-600">
                                        A look at the gearbox evolution for my robotic arm project. Featured on top are the various iterations I’ve designed: two 40:1 cycloidal drives (NEMA 17 and 
                                        NEMA 23 variants), three 28:1 harmonic drives with specialized couplings, and a NEMA 11-powered 4:1 planetary gear. Each motor is integrated with a 
                                        rear-mounted MKS closed-loop FOC controller via CAN bus. The video below highlights early torque response testing—holding 15 lbs at a 0.5m moment 
                                        arm—alongside a close-up of the cycloidal drive.
                                    </p>
                                </div>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Linux</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Python</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Electronics</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Robotics</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Fusion 360</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">3D-Printing</span>
                            </div>
                        </div>

                        <!-- National Eclipse Balloon Project -->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        National Eclipse Balloon Project (NEBP) (Undergraduate Research)
                                    </h3>

                                    <div class="mt-1">
                                        <a href="https://peer.asee.org/authors/andrew-snowdy" target="_blank" class="text-xs font-bold tracking-widest text-blue-900 hover:text-blue-700 transition-colors">
                                            [ Paper ]
                                        </a>
                                    </div>
                                </div>
                                <span class="text-sm font-medium text-gray-500">2021-2024</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                The NEBP is a NASA and NSF-sponsored initiative designed to simulate a full-scale mission lifecycle through scientific ballooning during solar eclipses. 
                                Over a three-year tenure—culminating in my role as Team Lead—I managed the design, testing, and deployment of complex payloads for the 2023 and 2024 eclipses. 
                                My work focused on the Engineering Track, where our team was tasked with live-streaming high-altitude video and conducting autonomous atmospheric experiments. 
                                This role required balancing high-stakes technical requirements with the logistical challenges of field operations, ensuring system reliability in extreme 
                                stratospheric environments.
                            </p>
                            
                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                                <div>
                                    <div class="grid grid-cols-3 gap-4">
                                        <img src="images/nebp_erie_minutes_from_takeoff.jpg" alt="A balloon launch or related equipment" class="col-span-1 rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/nebp_erie_up_and_away.jpg" alt="Another view of the balloon launch" class="col-span-2 rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <p class="mt-4 text-sm text-gray-600">
                                        Our flight string consisted of a helium-filled balloon coupled to a venting system, a recovery parachute, and four modular cylindrical payloads. 
                                        Not pictured is the ground station, which utilized a dish (RocketModem 5.8 Ghz), patch (Tracking), and Yagi antenna (RFD 900 Mhz) mounted on a 
                                        2-DOF tracking system for real-time telemetry. The launch process required rigorous pre-flight checklists and on-site troubleshooting to ensure 
                                        system reliability during the critical eclipse window. We were fortunate to deploy this system across multiple states to capture data during 
                                        both the 2023 Annular and 2024 Total Solar Eclipses.
                                    </p>
                                </div>
    
                                <div>
                                    <div class="grid grid-cols-2 gap-4">
                                        <img src="images/nebp_eclipse_at_max_altitude.jpg" alt="Another side by side image C" class="rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/nebp_eclipse_at_max_altitude2.jpg" alt="Another side by side image D" class="rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <p class="mt-4 text-sm text-gray-600">
                                        Just a showcase of some of the images we captured, one of the moon's shadow onto the earth and the other is of the total eclipse.
                                    </p>
                                </div>

                                <div>
                                    <img src="images/nebp_ballooning_system.png" alt="A new placeholder image for a third NEBP/HASP visual" class="rounded-lg shadow-md w-full object-contain border">
                                    <p class="mt-4 text-sm text-gray-600">
                                        This system architecture diagram illustrates our multi-payload flight string and ground segment. The primary command-and-control uplink utilized an 
                                        Iridium satellite modem, which distributed data locally to payloads via a low-power XBee mesh network. For high-bandwidth data, we implemented a 
                                        multi-frequency downlink strategy: an RFD 900 MHz link for critical telemetry and state-of-health diagnostics, and a 5.8 GHz RocketModem for 
                                        real-time video streaming. To ensure mission success and payload recovery, we integrated redundant GPS trackers to mitigate the telemetry dropouts 
                                        frequently encountered in the stratospheric environment.
                                    </p>
                                </div>
                                
                                <div>
                                    <img src="images/nebp_iridium_testing.jpg" alt="A new placeholder image for a third NEBP/HASP visual" class="rounded-lg shadow-md w-full object-contain border">
                                    <p class="mt-4 text-sm text-gray-600">
                                        Testing of the Iridium and Vent/Cutdown subsystems. The Iridium satellite modem serves as the primary communication uplink, providing global GPS 
                                        positioning and command queuing via an email-based gateway. This data is bridged locally to other payloads via a low-power XBee mesh network. 
                                        The custom-designed, 3D-printed vent on the left is utilized for active altitude control by regulating gas release. Furthermore, the system 
                                        incorporates a redundant nichrome-wire cutdown mechanism. Upon command, the high-resistance wire is heated to sever the load-bearing flight 
                                        string, enabling immediate balloon release.
                                    </p>
                                </div>

                                <div>
                                    <div class="grid grid-cols-2 gap-4">
                                        <img src="images/nebp_vent_and_pcb.jpg" alt="New side by side image A" class="rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/nebp_rfd.jpg" alt="New side by side image B" class="rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <p class="mt-4 text-sm text-gray-600">
                                        On the right is the RFD900 telemetry module integrated with our sensor stack, including a barometer, IMU, and temperature sensors. This payload 
                                        ended up serving as our primary backbone for real-time flight diagnostics and was the most reliable data link throughout the mission. To the 
                                        left is the altitude control PCB, which I designed in Altium by reverse-engineering and optimizing legacy hardware models. This board interfaces 
                                        with a high-torque servo to actuate the helium release valve, enabling active station-keeping. The 3D-printed vent structure, designed to attach 
                                        directly to the balloon envelope, is visible in the background.
                                    </p>
                                </div>
                                
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">High-Altitude Balloons</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Atmospheric Science</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Python</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">C++</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Communications</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">PCB development</span>
                            </div>
                        </div>

                        <!-- A Novel Black-Start Approach -->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        A Novel Black-Start Approach for Inverter-Based Microgrids (Undergraduate Capstone)
                                    </h3>
                                </div>
                                <span class="text-sm font-medium text-gray-500">2023-2024</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                This project introduces a novel black-start method for inverter-based microgrids to improve resiliency and rapid power restoration after a blackout. 
                                The goal was to design a grid control scheme using multiple grid-forming (GFM) inverters, specifically addressing the instability challenges found 
                                in microgrids with high inverter saturation. The system was implemented using a TI C2000 F28379D controller to send PWM signals to a BOOSTXL-3PHGaNINV 
                                inverter, successfully forming a stable grid.
                            </p>
                            
                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                                <div>
                                    <img src="images/blackstart_system_design_overview.png" alt="System design overview diagram" class="rounded-lg shadow-md w-full object-contain">
                                    <p class="mt-4 text-gray-600">
                                        This system diagram shows the overall design, consisting of two microgrids with a total of five inverters. Each inverter has its own filter, 
                                        transformer, and relay, allowing for a staged, bottom-up black-start sequence to restore power reliably.
                                    </p>
                                </div>

                                <div>
                                    <div class="grid grid-cols-2 gap-4">
                                        <img src="images/blackstart_start_pathway.png" alt="Diagram of the black-start sequence" class="col-span-2 rounded-lg shadow-md w-full object-contain">
                                        <img src="images/blackstart_inverter_1_1_voltage.png" alt="Graph of anchor inverter voltage" class="rounded-lg shadow-md w-full object-contain">
                                        <img src="images/blackstart_inverter_1_1_current.png" alt="Graph of anchor inverter current" class="rounded-lg shadow-md w-full object-contain">
                                    </div>
                                    <p class="mt-4 text-gray-600">
                                        The black-start sequence at the top demonstrates the bottom-up grid restoration technique implemented in this study. The lower measurements show 
                                        the interconnection voltage and current for one of the microgrids. As each new inverter connects at the labeled intervals, a brief transient 
                                        occurs, followed rapidly by a stable, three-phase 60Hz signal with minimal harmonic distortion. This demonstrates the effectiveness of the 
                                        decentralized droop control in achieving seamless synchronization.
                                    </p>
                                </div>
                                
                                <div>
                                    <div class="grid grid-cols-1 sm:grid-cols-2 gap-4">
                                        <img src="images/blackstart_grid_output_voltage.png" alt="Graph of final grid output voltage" class="rounded-lg shadow-md w-full object-contain">
                                        <img src="images/blackstart_grid_output_frequency.png" alt="Graph of final grid output frequency" class="rounded-lg shadow-md w-full object-contain">
                                    </div>
                                    <p class="mt-4 text-gray-600">
                                        This figure illustrates the final synchronization of both microgrids to form a complete, interconnected grid. As shown in the frequency plot, 
                                        the system successfully recovers from a 0.4 Hz transient during the interconnection phase, with the droop controllers acting to stabilize the 
                                        frequency back to a steady-state 60 Hz. The corresponding voltage waveforms confirm that the system achieves stable synchronization shortly 
                                        after the final relay closure, resulting in a reliable three-phase output that meets service standards.
                                    </p>
                                </div>

                                <div>
                                    <div class="space-y-4">
                                        <div class="grid grid-cols-3 gap-4">
                                            <img src="images/blackstart_microcontroller_system_overview.png" alt="Block diagram of the microcontroller system" class="col-span-1 rounded-lg shadow-md w-full h-full object-cover">
                                            <img src="images/blackstart_droop_control.png" alt="Simulink model of droop control" class="col-span-2 rounded-lg shadow-md w-full h-full object-cover">
                                        </div>
                                        
                                        <img src="images/blackstart_voltage_and_current_control.png" alt="Simulink model of current and voltage control loops" class="rounded-lg shadow-md w-full object-contain">
                                    </div>
                                    <p class="mt-4 text-gray-600">
                                        The system control architecture is outlined in the top-left block diagram, detailing the signal flow from sensor feedback to PWM generation. 
                                        To its right, the droop controller regulates frequency, active power, and reactive power based on inputs derived from the Clarke and Park transforms, 
                                        which convert three-phase AC measurements into a stationary dq reference frame. The resulting setpoints are fed into the nested control loops 
                                        shown in the lower diagram. These loops regulate voltage and current through a series of PI controllers and anti-windup logic, ultimately producing 
                                        the PWM signals required by the inverter boards for a stable three-phase power signal.
                                    </p>
                                </div>
                                
                                <div>
                                    <div class="grid grid-cols-1 gap-4">
                                        <img src="images/blackstart_controller_inverter_unit.png" alt="Texas Instruments C2000 controller and BOOSTXL-3PHGaNINV inverter unit" class="rounded-lg shadow-md w-full object-contain">
                                        <img src="images/blackstart_full_electrical_setup.png" alt="Full electrical setup for the black-start project" class="rounded-lg shadow-md w-full object-contain">
                                    </div>
                                    <p class="mt-4 text-gray-600">
                                        The top image displays the full assembly of a single inverter unit, featuring a custom-designed PCB that integrates the LC filter, sensors, isolation 
                                        delta-wye transformer, and connection relay. We fabricated five identical inverters to test collective grid-forming capabilities. The bottom image 
                                        shows the complete experimental setup, where the five units are organized into two distinct microgrids. This system includes dedicated DC power 
                                        supplies, static loads, and a central interconnect relay to manage the synchronization of the two microgrids.
                                    </p>
                                </div>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Power Electronics</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Controls</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Matlab</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Simulink</span>
                            </div>
                        </div>
                        
                        <!-- Nixie Tube Clock Project -->
                        <div class="border-b border-gray-200 pb-12"> 
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        Nixie Tube Clock Build
                                    </h3>
                                </div>
                                <span class="text-sm font-medium text-gray-500">2022</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                Nixie tubes are fascinating to me; the unique glow they emit is unlike anything else. When I decided to build a clock for myself, I learned a great deal 
                                about the engineering lifecycle—from initial breadboard prototyping to designing a custom PCB and integrating all the components into a compact enclosure. 
                                This project was a perfect way to deepen my understanding of electrical engineering and system integration.
                            </p>
                            
                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                                <div>
                                    <img src="images/nixie_dark.jpg" alt="Nixie tube clock illuminated in the dark" class="rounded-lg shadow-md w-full object-contain border">
                                    <p class="mt-4 text text-gray-600">
                                        Shown above is the completed Nixie tube clock, housed in a custom 3D-printed chassis. The system is powered by a standard 12V DC input. On the top-right 
                                        of the case, I integrated the switch and encoder (repurposed from a broken mouse) to allow for manual time adjustments and user interaction.
                                    </p>
                                </div>
                                <div>
                                    <div class="grid grid-cols-2 gap-4">
                                        <img src="images/nixie_top.jpg" alt="New side by side image A for Nixie clock" class="rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/nixie_bottom.jpg" alt="New side by side image B for Nixie clock" class="rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <p class="mt-4 text text-gray-600">
                                        I designed this custom PCB in Altium, centered around an Arduino Mega microcontroller. The board integrates a Real-Time Clock (RTC), a 12V-to-240V high-voltage 
                                        converter, and a BCD-to-decimal driver IC to control the Nixie tubes. For the user interface, I repurposed the scroll wheel and switch from a broken mouse 
                                        to act as a rotary encoder. I then programmed the firmware to handle manual time adjustments, internal drift, and Daylight Savings transitions.
                                    </p>
                                </div>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Electronics</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Soldering</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Arduino</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">C++</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">PCB Design</span>
                            </div>
                        </div>

                        <!-- Intelligent Ground Vehicle Project -->
                        <div class="border-b border-gray-200 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        Intelligent Ground Vehicle (Gannon University Club)
                                    </h3>
                                </div>
                                <span class="text-sm font-medium text-gray-500">2023</span>
                            </div>
                            <p class="mt-1 text-gray-600">
                                I led the electrical engineering in the Intelligent Ground Vehicle competition for a semester in which I augmented the current design of a modified electrical wheel 
                                chair to include saftey precautions of an emergancy stop and wireless stop. Portions of hardware and software was completed by students from years prior. 
                                We achieved fourth place in the competition
                            </p>

                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                                <div>
                                   <div class="grid grid-cols-4 gap-4">
                                        <img src="images/igv_robbot.png" alt="The full Intelligent Ground Vehicle robot" class="col-span-2 rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/igv_nrf.png" alt="The nRF radio transceiver wired to an Arduino" class="col-span-1 rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/igv_nrf_box.png" alt="The 'Steve Stopper' emergency stop box" class="col-span-1 rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <p class="mt-4 text-gray-600">
                                        The full IGV platform (left), the nRF radio transceiver (middle), and the custom 'Steve Stopper' wireless emergency stop (right). I designed the proto board 
                                        and software with safety as the primary requirement. To prevent runaways, the system includes an automatic heartbeat-loss failsafe that stops the robot if 
                                        it goes out of range. Additionally, the box features a manual power shutoff linked to an onboard relay for immediate hardware-level disconnection.
                                    </p>
                                </div>
                                
                                <div>
                                    <img src="images/igv_schematic.png" alt="High-level electrical schematic for the Intelligent Ground Vehicle" class="rounded-lg shadow-md w-full object-contain">
                                    <p class="mt-4 text-gray-600">
                                        The high-level electrical schematic, illustrating the power distribution and safety circuits for the Intelligent Ground Vehicle. 12v lead-acid battteries 
                                        were used to power the wheelchair base, giving us more than enough power to carry the required 20 lb payload.
                                    </p>
                                </div>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2"> 
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Arduino</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Controls</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Electronics</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Communications</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Safety Systems</span>
                            </div>
                        </div>

                        <!-- Drone Build Project -->
                        <div class="border-b-0 pb-12">
                            <div class="flex justify-between items-center">
                                <div>
                                    <h3 class="text-xl font-bold text-slate-800">
                                        Drone Build
                                    </h3>
                                </div>
                                <span class="text-sm font-medium text-gray-500">2020</span>
                            </div>
                            <p class="mt-4 text-gray-600">
                                Towards the end of highschool I became very interested in drones, deciding to build one myself. I curtailed parts to my own liking, sticking with 4s lipo batteries, 
                                eco motors and a stack esc and controller - a mid powered drone with everything a true race FPV drone had. After flying obsesively and crashing frequenly I 
                                decided to design disposable 3D printed protectors for expendages and a stronger antenna mount. As well as going in depth tuning, using getfpv software linked 
                                to my controller.
                            </p>
                            
                            <div class="mt-8 space-y-8 max-w-3xl mx-auto">
                                <div>
                                    <img src="images/drone_without_top.jpg" alt="Custom built FPV drone assembled" class="rounded-lg shadow-md w-full object-contain">
                                    <p class="mt-4 text-gray-600">
                                        The assembled drone above is the final product. After researching components to find an optimal balance of power, durability, and cost, I selected high-KV 
                                        brushless motors and a lightweight for responsive thrust. The build features an ESC + MCU stack integration, where I carefully managed cable routing to 
                                        minimize EMI and ensure durability during high-G maneuvers. I also integrated a custom 3D-printed mounting for the FPV camera and antennas.
                                    </p>
                                </div>

                                <div>
                                    <div class="grid grid-cols-2 grid-rows-2 gap-4">
                                       <img src="images/drone.png" alt="Drone with top plate removed" class="row-span-2 rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/drone_antenna.png" alt="3D printed antenna mount" class="rounded-lg shadow-md w-full h-full object-cover">
                                        <img src="images/drone_wing_protection.png" alt="3D printed arm protectors" class="rounded-lg shadow-md w-full h-full object-cover">
                                    </div>
                                    <p class="mt-4 text-gray-600">
                                        After crash landing and running into trees, I decided it would be best to print protection for the most frequently impacted parts. Prior to these parts I 
                                        used a lot of hot glue and some plastic drinking straws to hold up antennas.
                                    </p>
                                </div>
                            </div>

                            <div class="mt-6 flex flex-wrap gap-2">
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">3D Printing</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Betaflight</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">CAD</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Soldering</span>
                                <span class="text-sm bg-gray-200 text-gray-800 px-2 py-1 rounded-md">Electronics</span>
                            </div>
                        </div>

                    </div>
                </section>
            </div>
        </main>
    </div>

</body>
</html>

